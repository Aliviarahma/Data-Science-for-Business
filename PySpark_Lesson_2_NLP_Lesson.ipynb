{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "35.0 Case Study 20 - PySpark Lesson 2 - NLP Lesson.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Aliviarahma/DataScienceforBusiness/blob/Big-Data/PySpark_Lesson_2_NLP_Lesson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSd8J4GBDqbB"
      },
      "source": [
        "# Spark NLP - News Headline Categorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4AWl8KkE5DB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "cb0b460d-80f0-4213-ef20-0a140035df4e"
      },
      "source": [
        "# Install Pyspark & Setup our Java Environment - Takes around 15 seconds\n",
        "\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "# Note please go to https://spark.apache.org/downloads.html\n",
        "# And check to see if the version number has been updated, if so update the link below with the new version number\n",
        "!wget -q https://www-us.apache.org/dist/spark/spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.4-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.4-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tar: spark-2.4.4-bin-hadoop2.7.tgz: Cannot open: No such file or directory\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/findspark.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mpy4j\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspark_python\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lib\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"py4j-*.zip\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2916d84bf023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SPARK_HOME\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/spark-2.4.4-bin-hadoop2.7\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfindspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mfindspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/findspark.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    161\u001b[0m             raise Exception(\n\u001b[1;32m    162\u001b[0m                 \"Unable to find py4j in {}, your SPARK_HOME may not be configured correctly\".format(\n\u001b[0;32m--> 163\u001b[0;31m                     \u001b[0mspark_python\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                 )\n\u001b[1;32m    165\u001b[0m             )\n",
            "\u001b[0;31mException\u001b[0m: Unable to find py4j in /content/spark-2.4.4-bin-hadoop2.7/python, your SPARK_HOME may not be configured correctly"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X5-obbWFDxm"
      },
      "source": [
        "from pyspark.ml import Pipeline \n",
        "from pyspark.ml.feature import CountVectorizer,StringIndexer, RegexTokenizer,StopWordsRemover\n",
        "from pyspark.sql.functions import col, udf,regexp_replace,isnull\n",
        "from pyspark.sql.types import StringType,IntegerType\n",
        "from pyspark.ml.classification import NaiveBayes\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiPpRLoXGrr6"
      },
      "source": [
        "spark = SparkSession.builder.master(\"local[*]\").appName(\"Spark NLP News Data\").getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gDW95QyEe_a"
      },
      "source": [
        "# Obtain our data\n",
        "\n",
        "news_data = spark.read.csv(s3_bucket_path,header = 'True',inferSchema='True')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdtZz0uEFMvH"
      },
      "source": [
        "news_data.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mjf8_8LFM17"
      },
      "source": [
        "news_data.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bq9qQHSLFM7O"
      },
      "source": [
        "title_category = news_data.select(\"TITLE\",\"CATEGORY\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QnEcKxnFNA_"
      },
      "source": [
        "title_category.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Arn_1SCFUUU"
      },
      "source": [
        "\n",
        "Let's check null values in TITLE and CATEGORY columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfvwnInvFM_F"
      },
      "source": [
        "def null_value_count(df):\n",
        "  null_columns_counts = []\n",
        "  numRows = df.count()\n",
        "  for k in df.columns:\n",
        "    nullRows = df.where(col(k).isNull()).count()\n",
        "    if(nullRows > 0):\n",
        "      temp = k,nullRows\n",
        "      null_columns_counts.append(temp)\n",
        "  return(null_columns_counts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "353j7MMsFQ-i"
      },
      "source": [
        "null_columns_count_list = null_value_count(title_category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMhcbLLVFRCL"
      },
      "source": [
        "spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1XEdoaZFZkx"
      },
      "source": [
        "\n",
        "There are 389 empty titles and 516 categories\n",
        "\n",
        "Let's drop/delete the null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbllQWN2FRFL"
      },
      "source": [
        "title_category = title_category.dropna()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJeciuICFRIK"
      },
      "source": [
        "title_category.count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uumBQkW5FROV"
      },
      "source": [
        "title_category.show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVBCZA6eFRWN"
      },
      "source": [
        "title_category.select(\"Category\").distinct().count()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZRAarg5Fkhv"
      },
      "source": [
        "\n",
        "Top 20 news categories"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSoAEUTAFRZY"
      },
      "source": [
        "title_category.groupBy(\"Category\").count().orderBy(col(\"count\").desc()).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJaqcJWGFpsR"
      },
      "source": [
        "Top 20 news title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU-HAhnIFRdL"
      },
      "source": [
        "title_category.groupBy(\"TITLE\").count().orderBy(col(\"count\").desc()).show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9ShbypDFsyx"
      },
      "source": [
        "## Data Cleaning\n",
        "1. Removing numbers from titles\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpQvcwPiFRfo"
      },
      "source": [
        "title_category = title_category.withColumn(\"only_str\",regexp_replace(col('TITLE'), '\\d+', ''))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWG1dj3lFRix"
      },
      "source": [
        "title_category.select(\"TITLE\",\"only_str\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8xdvFIGF3-g"
      },
      "source": [
        "Split text into words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYLJEpQcFRp5"
      },
      "source": [
        "regex_tokenizer = RegexTokenizer(inputCol=\"only_str\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "raw_words = regex_tokenizer.transform(title_category)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAykZP62FRuy"
      },
      "source": [
        "raw_words.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZi0gUJBF6Ns"
      },
      "source": [
        "\n",
        "Remove stop words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxZ7HunBFRxh"
      },
      "source": [
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "words_df = remover.transform(raw_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8empeW6FR00"
      },
      "source": [
        "words_df.select(\"words\",\"filtered\").show(truncate=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iB2NO4WqF96t"
      },
      "source": [
        "\n",
        "Now lets encode column of category to a column of category indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jx6HljzsFM5J"
      },
      "source": [
        "feature_data.select(\"CATEGORY\",\"categoryIndex\").show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "To_-Ng9FGH-N"
      },
      "source": [
        "\n",
        "Convert text into vectors of token counts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-wo2AZOF_72"
      },
      "source": [
        "cv = CountVectorizer(inputCol=\"filtered\", outputCol=\"features\")\n",
        "model = cv.fit(words_label_index)\n",
        "countVectorizer_feateures = model.transform(words_label_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPw__hm6GM-_"
      },
      "source": [
        "\n",
        "Create our Training & Test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI5nTKZZGAFn"
      },
      "source": [
        "(trainingData, testData) = countVectorizer_feateures.randomSplit([0.8, 0.2],seed = 11)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPFQcun3GTkB"
      },
      "source": [
        "## Train our Model and Evaluate it's performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-74HkpQGALQ"
      },
      "source": [
        "nb = NaiveBayes(modelType=\"multinomial\",labelCol=\"categoryIndex\", featuresCol=\"features\")\n",
        "nbModel = nb.fit(trainingData)\n",
        "nb_predictions = nbModel.transform(testData)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frp01nF_GAQv"
      },
      "source": [
        "nb_predictions.select(\"prediction\", \"categoryIndex\", \"features\").show(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5I2wtBjGAU2"
      },
      "source": [
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"categoryIndex\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "nb_accuracy = evaluator.evaluate(nb_predictions)\n",
        "print(\"Accuracy of NaiveBayes is = %g\"% (nb_accuracy))\n",
        "print(\"Test Error of NaiveBayes = %g \" % (1.0 - nb_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-9bD0sNGAYd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Op6E3sD6GAbq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcqMfD6MGAfg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qny-Sod6GAjU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5EdWfzqGAm0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}